#' Variable selection algorithm with a predefined component loading structure
#'
#' Variable selection algorithm when the common/distinctive structure is known a priori.
#' The common component can also be sparse, which is to be estimated by Lasso.
#' The distinctive components are not sparse in the sense that the entire variables in a component (belonging to a certain block) are either all zeros or non-zeros.
#'
#'@param DATA A matrix, which contains the concatenated data with the same subjects from multiple blocks.
#'@param Jk A vector containing number of variables in the concatinated data matrix.
#'@param R Number of components.
#'@param CommPosition A scaler or a vector indicating with column(s) in the component loading matrix (P) is the common component
#'@param GroupStructure A matrix indicating the predefined common/distinctive structure in the
#'component loading matrix (P). This matrix can be generated by the function \code{component_structure}.
#'@param LASSO A Lasso tuning parameter for the common component. If Lasso=0, then the common component
#'will not be sparse. In case user wants to generate a vector of Lasso parameters and performs a cross-validation,
#'then please use the \code{crossvali} function, which incorporates \code{CDpre} algorithm.
#'@param MaxIter The maximum rounds of iterations. It should be a positive integer. The default value is 400.
#'
#'@return
#'\item{Pmatrix}{Estimated component loading matrix (i.e., P).}
#'\item{Tmatrix}{Estimated component score matrix (i.e., T).}
#'\item{Lossvec}{A vector containing the loss in each iteration.}
#'
#'@examples
#'CDpre(DATA, Jk, R, CommPosition, GroupStructure, LASSO, MaxIter)
#'
#'@references
#'Gu, Z., & Van Deun, K. (2016). A variable selection method for simultaneous component based data integration. \emph{Chemometrics and Intelligent Laboratory Systems}, 158, 187-199.

CDpre <- function(DATA, Jk, R, CommPosition, GroupStructure, LASSO, MaxIter){

  DistPosition <- setdiff(1:R, CommPosition)
  I_Data <- dim(DATA)[1]
  sumJk <- dim(DATA)[2]
  eps <- 10^(-12)

  if(missing(MaxIter)){
    MaxIter <- 400
  }

  #initialize P, Lossc
  P <- matrix(rnorm(sumJk * R), nrow = sumJk, ncol = R)
  P[GroupStructure == 0]<-0
  Pt <- t(P)

  PIndexforLasso <- Pt
  PIndexforLasso[CommPosition, ] <- 1
  PIndexforLasso[DistPosition, ] <- 0
  PIndexforGLasso <- Pt #note that the distinctive structure is predefined.
  PIndexforGLasso[CommPosition, ] <- 0
  PIndexforGLasso[DistPosition, ] <- 1

  #absP <- abs(P)
  pen1 <- LASSO*sum(abs(P[, CommPosition]))
  sqP <- P^2
  L <- 1
  #sumpk <- array()
  #sqrtpk <- matrix(NA, nrow = 1, ncol = length(Jk))
  #for (i in 1:length(Jk)){

    #U <- L + Jk[i] - 1
    #sqP4Dist <- sqP
    #sqP4Dist[ , CommPosition] <- 0
    #sqrtsumP <- sqrt(colSums(sqP4Dist[L:U, ]))/sqrt(Jk[i])
    #sqrtsumPDist <- sqrt(colSums(sqP4Dist[L:U, DistPosition]))/sqrt(Jk[i])
    #sqrtpk[, i] <- matrix(1, Jk[i], 1) %*% sqrtsumP
    #L <- U + 1

  #}

  residual <- sum(DATA^2)
  Lossc <- residual + pen1

  conv <- 0
  iter <- 1
  Lossvec <- array()

  while (conv == 0){

    #update Tmat, note that Tmax refers to T matrix
    if (LASSO == 0){
      SVD_DATA <- svd(DATA, R, R)  #note this is different from the matlab svds function. need to test it!!
      Tmat <- SVD_DATA$u
    }
    else {
      A <- Pt %*% t(DATA)
      SVD_DATA <- svd(A, R, R)
      Tmat <- SVD_DATA$v %*% t(SVD_DATA$u)
    }

    residual <- sum((DATA - Tmat %*% Pt)^2)
    Lossu <- residual + pen1

    #update P
    if (LASSO == 0){
      P <- t(DATA) %*% Tmat
      P[GroupStructure == 0] <- 0  # this is to keep the zero structures
      Pt <- t(P)
    }
    else{

      for (r in 1:R){
        if (r %in% CommPosition) {
          for (j in 1:sumJk){
            ols <- t(DATA[, j]) %*% Tmat[, r]
            Lambda <- 0.5 * LASSO
            if (ols < 0 & abs(ols) > Lambda) {
              P[j, r] <- ols + Lambda
            }
            else if (ols > 0 & abs(ols) > Lambda) {
              P[j, r] <- ols - Lambda
            }
            else {
              P[j, r] <- 0
            }
          }
        }
        else {
          for (j in 1:sumJk){
            P[j, r] <- t(DATA[, j]) %*% Tmat[, r] #note that in the original matlab file this term is devided by sumD(=1)
          }
        }
      }
    }

    P[GroupStructure == 0] <- 0
    Pt <- t(P)

    #absP <- abs(P)
    pen1 <- LASSO*sum(abs(P[, CommPosition]))
    sqP <- P^2

    L <- 1
    #sumpk <- array()
   # sqrtpk <- matrix()
    #for (i in 1:length(Jk)){

     # U <- L + Jk[i] - 1
     # sqP4Dist <- sqP
     # sqP4Dist[ , CommPosition] <- 0
     # sqrtsumP <- sqrt(colSums(sqP4Dist[L:U, ]))/sqrt(Jk[i])
     # sqrtsumPDist <- sqrt(colSums(sqP4Dist[L:U, DistPosition]))/sqrt(Jk[i])
     # sqrtpk[, i] <- matrix(1, Jk[i], 1) %*% sqrtsumP
     # L <- U + 1
    #}
    residual <- sum((DATA - Tmat %*% Pt)^2)
    Lossu2 <- residual + pen1

    #check convergence
    if (abs(Lossc-Lossu)< 10^(-9)) {
      Loss <- Lossu
      residual <- residual
      lassopen <- pen1
      P[abs(P) <= 2 * eps] <- 0
      conv <- 1
    }
    else if (iter > MaxIter | LASSO == 0){
      Loss <- Lossu
      residual <- residual
      lassopen <- pen1
      P[abs(P) <= 2 * eps] <- 0
      conv <- 1
    }

    Lossvec[iter] <- Lossu
    iter <- iter + 1
    Lossc <- Lossu2
  }

  return_varselect <- list()
  return_varselect$Pmatrix <- P
  return_varselect$Tmatrix <- Tmat
  #return_varselect$Loss <- Loss
  return_varselect$Lossvec <- Lossvec
  #return_varselect$residual <- residual
  #return_varselect$lassopen <- lassopen
  #return_varselect$iter <- iter - 1
  return(return_varselect)

}
